{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZjJhlFUZKAK",
        "outputId": "47b341b0-1754-4c43-d3e7-aac6785d95e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted URLs: ['https://www.sailmagazine.com/boats/best-boats-2023', 'https://www.reddit.com/r/sailing/comments/17r2eu0/what_brands_make_strong_reliable_boats_for_actual/', 'https://www.reddit.com/r/sailing/comments/vou859/best_sailboat_type_for_a_circumnavigation/', 'https://www.reddit.com/r/sailing/comments/zo9v9u/best_starter_boat/', 'https://www.reddit.com/r/sailing/comments/p3fou5/best_large_sail_boat_to_sail_the_world/', 'https://www.reddit.com/r/sailing/comments/1631696/what_brand_of_yacht_is_equivalent_to_a_rolls/', 'https://www.yachtingworld.com/yachts-and-gear/5-best-family-cruising-yachts-of-2022-137286', 'https://www.cruisingworld.com/sailboats/40-best-sailboats/', 'https://itboat.com/explore/14-luxury-sailing-yachts', 'https://www.boatinternational.com/yachts/the-register/top-largest-sailing-yachts--25057']\n",
            "Fetching content from: https://www.sailmagazine.com/boats/best-boats-2023\n",
            "Fetching content from: https://www.reddit.com/r/sailing/comments/17r2eu0/what_brands_make_strong_reliable_boats_for_actual/\n",
            "Fetching content from: https://www.reddit.com/r/sailing/comments/vou859/best_sailboat_type_for_a_circumnavigation/\n",
            "Fetching content from: https://www.reddit.com/r/sailing/comments/zo9v9u/best_starter_boat/\n",
            "Fetching content from: https://www.reddit.com/r/sailing/comments/p3fou5/best_large_sail_boat_to_sail_the_world/\n",
            "Fetching content from: https://www.reddit.com/r/sailing/comments/1631696/what_brand_of_yacht_is_equivalent_to_a_rolls/\n",
            "Fetching content from: https://www.yachtingworld.com/yachts-and-gear/5-best-family-cruising-yachts-of-2022-137286\n",
            "Fetching content from: https://www.cruisingworld.com/sailboats/40-best-sailboats/\n",
            "Fetching content from: https://itboat.com/explore/14-luxury-sailing-yachts\n",
            "Fetching content from: https://www.boatinternational.com/yachts/the-register/top-largest-sailing-yachts--25057\n",
            "Most common words in the top 10 search results (appearing in at least 3 sites):\n",
            "blocked: 10 (in 5 sites)\n",
            "file: 10 (in 5 sites)\n",
            "ticket: 10 (in 5 sites)\n",
            "below: 9 (in 7 sites)\n",
            "think: 7 (in 7 sites)\n",
            "look: 7 (in 7 sites)\n",
            "network: 5 (in 5 sites)\n",
            "log: 5 (in 5 sites)\n",
            "reddit: 5 (in 5 sites)\n",
            "account: 5 (in 5 sites)\n",
            "developer: 5 (in 5 sites)\n",
            "tokenif: 5 (in 5 sites)\n",
            "\n",
            "\n",
            "Most common bigrams in the top 10 search results (appearing in at least 3 sites):\n",
            "file ticket: 10 (in 5 sites)\n",
            "blocked network: 5 (in 5 sites)\n",
            "network log: 5 (in 5 sites)\n",
            "log reddit: 5 (in 5 sites)\n",
            "reddit account: 5 (in 5 sites)\n",
            "account developer: 5 (in 5 sites)\n",
            "developer tokenif: 5 (in 5 sites)\n",
            "tokenif think: 5 (in 5 sites)\n",
            "think blocked: 5 (in 5 sites)\n",
            "blocked file: 5 (in 5 sites)\n",
            "ticket below: 5 (in 5 sites)\n",
            "below look: 5 (in 5 sites)\n",
            "look file: 5 (in 5 sites)\n",
            "\n",
            "\n",
            "Most common trigrams in the top 10 search results (appearing in at least 3 sites):\n",
            "blocked network log: 5 (in 5 sites)\n",
            "network log reddit: 5 (in 5 sites)\n",
            "log reddit account: 5 (in 5 sites)\n",
            "reddit account developer: 5 (in 5 sites)\n",
            "account developer tokenif: 5 (in 5 sites)\n",
            "developer tokenif think: 5 (in 5 sites)\n",
            "tokenif think blocked: 5 (in 5 sites)\n",
            "think blocked file: 5 (in 5 sites)\n",
            "blocked file ticket: 5 (in 5 sites)\n",
            "file ticket below: 5 (in 5 sites)\n",
            "ticket below look: 5 (in 5 sites)\n",
            "below look file: 5 (in 5 sites)\n",
            "look file ticket: 5 (in 5 sites)\n"
          ]
        }
      ],
      "source": [
        "import subprocess\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from collections import Counter, defaultdict\n",
        "from nltk.util import bigrams, trigrams\n",
        "import nltk\n",
        "from googlesearch import search\n",
        "\n",
        "# Download NLTK data if not already installed\n",
        "nltk.download('punkt')\n",
        "\n",
        "# List of common words and phrases to exclude\n",
        "EXCLUSION_LIST = {\n",
        "    'the', 'and', 'a', 'of', 'to', 'in', 'with', 'for', 'is', 'that',\n",
        "    'this', 'it', 'best', 'as', 'you', 'on', 'was', 'are', 'by', 'an',\n",
        "    'at', 'be', 'from', 'or', 'if', 'not', 'have', 'had', 'has', 'but',\n",
        "    'they', 'their', 'we', 'our', 'his', 'her', 'which', 'about', 'will',\n",
        "    'would', 'can', 'all', 'more', 'what', 'when', 'who', 'one', 'do',\n",
        "    'he', 'she', 'them', 'out', 'so', 'up', 'no', 'into', 'my', 'your',\n",
        "    'there', 'use', 'how', 'time', 'just', 'like', 'some', 'other', 'than',\n",
        "    'also', 'could', 'new', 'any', 'very', 'only', 'get', 'see', 'because',\n",
        "    'been', 'people', 'these', 'over', 'its', 'even', 'most', 'me', 'back',\n",
        "    'here', 'after', 'us', 'such', 'where', 'go', 'way', 'many', 'those',\n",
        "    'full review', 'enable js', 'js disable', 'disable ad', 'ad blocker',\n",
        "    'skip content', 'digital edition', 'privacy policy', 'enable js disable',\n",
        "    'js disable ad', 'disable ad blocker', 'js', 'disable', 'ad', 'blocker',\n",
        "    'privacy', 'content', 'rights', 'settings', 'went', 'policy', 'own',\n",
        "    'pick', 'contact', 'edition'\n",
        "}\n",
        "\n",
        "# Function to search Google and return the top 10 results\n",
        "def search_google(query):\n",
        "    urls = list(search(query, num=10, stop=10, pause=2))\n",
        "    print(f\"Extracted URLs: {urls}\")\n",
        "    return urls\n",
        "\n",
        "# Function to fetch the content of each page\n",
        "def fetch_page_content(url):\n",
        "    headers = {\n",
        "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
        "    }\n",
        "    response = requests.get(url, headers=headers)\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "    for script in soup([\"script\", \"style\"]):\n",
        "        script.decompose()\n",
        "    return soup.get_text()\n",
        "\n",
        "# Function to count words, bigrams, and trigrams in a text\n",
        "def count_words_bigrams_trigrams(text):\n",
        "    words = [word for word in text.lower().split() if word.isalpha() and word not in EXCLUSION_LIST]\n",
        "    word_counts = Counter(words)\n",
        "    bigram_counts = Counter(bigrams(words))\n",
        "    trigram_counts = Counter(trigrams(words))\n",
        "    return word_counts, bigram_counts, trigram_counts\n",
        "\n",
        "# Main function\n",
        "def main(query, min_sites=1):\n",
        "    results = search_google(query)\n",
        "    word_site_counts = defaultdict(lambda: defaultdict(int))\n",
        "    bigram_site_counts = defaultdict(lambda: defaultdict(int))\n",
        "    trigram_site_counts = defaultdict(lambda: defaultdict(int))\n",
        "\n",
        "    for url in results:\n",
        "        try:\n",
        "            print(f\"Fetching content from: {url}\")\n",
        "            page_content = fetch_page_content(url)\n",
        "            word_counts, bigram_counts, trigram_counts = count_words_bigrams_trigrams(page_content)\n",
        "\n",
        "            for word, count in word_counts.items():\n",
        "                word_site_counts[word][url] += count\n",
        "            for bigram, count in bigram_counts.items():\n",
        "                bigram_site_counts[bigram][url] += count\n",
        "            for trigram, count in trigram_counts.items():\n",
        "                trigram_site_counts[trigram][url] += count\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to fetch {url}: {e}\")\n",
        "\n",
        "    def aggregate_counts(site_counts):\n",
        "        aggregated = {}\n",
        "        for item, counts in site_counts.items():\n",
        "            aggregated[item] = (len(counts), sum(counts.values()))\n",
        "        return aggregated\n",
        "\n",
        "    aggregated_words = aggregate_counts(word_site_counts)\n",
        "    aggregated_bigrams = aggregate_counts(bigram_site_counts)\n",
        "    aggregated_trigrams = aggregate_counts(trigram_site_counts)\n",
        "\n",
        "    def print_top_items(aggregated, label, min_sites):\n",
        "        sorted_items = sorted(aggregated.items(), key=lambda x: x[1][1], reverse=True)\n",
        "        print(f\"Most common {label} in the top 10 search results (appearing in at least {min_sites} sites):\")\n",
        "        for item, (site_count, total_count) in sorted_items:\n",
        "            if site_count >= min_sites:\n",
        "                print(f\"{' '.join(item) if isinstance(item, tuple) else item}: {total_count} (in {site_count} sites)\")\n",
        "\n",
        "    print_top_items(aggregated_words, \"words\", min_sites)\n",
        "    print(\"\\n\")\n",
        "    print_top_items(aggregated_bigrams, \"bigrams\", min_sites)\n",
        "    print(\"\\n\")\n",
        "    print_top_items(aggregated_trigrams, \"trigrams\", min_sites)\n",
        "\n",
        "# Settings\n",
        "query = \"Best sailing yachts\"\n",
        "min_sites = 3  # Set the minimum number of sites a keyword must appear on to be listed\n",
        "main(query, min_sites)\n"
      ]
    }
  ]
}